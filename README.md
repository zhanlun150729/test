<div align="center">
  <img src="assets/logo.png" alt="MMKG-RDS Logo" width="150" height="150">
  
  # MMKG-RDS
  
  ### ğŸ§  Reasoning Data Synthesis via Deep Mining of Multimodal Knowledge Graphs
  
  [![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
  [![Python](https://img.shields.io/badge/Python-3.8%2B-brightgreen.svg)](https://www.python.org/)
  [![GitHub Stars](https://img.shields.io/github/stars/yourusername/MMKG-RDS?style=social)](https://github.com/360AILAB-NLP/MMKG-RDS)
  
  [English](README.md) | [ä¸­æ–‡](README_zh.md)
</div>

---

## ğŸ“– Table of Contents

- [Overview](#-overview)
- [Key Features](#-key-features)
- [Pipeline](#-pipeline)
- [Quick Start](#-quick-start)
- [Project Structure](#-project-structure)
- [Benchmark Results](#-benchmark-results)
- [Citation](#-citation)
- [License](#-license)

---

## ğŸ¯ Overview

Synthesizing high-quality training data is crucial for enhancing domain models' reasoning abilities. Existing methods face limitations in **long-tail knowledge coverage**, **effectiveness verification**, and **interpretability**. Knowledge-graph-based approaches still fall short in functionality, granularity, customizability, and evaluation.

To address these issues, we propose **MMKG-RDS**â€”a flexible framework for reasoning data synthesis that leverages multimodal knowledge graphs. It supports fine-grained knowledge extraction, customizable path sampling, and multidimensional data quality scoring.

<div align="center">
  <img src="assets/framwork.png" alt="MMKG-RDS Framework" width="800">
</div>

### ğŸ“ MMKG-RDS-Bench Dataset

We validate MMKG-RDS with the **MMKG-RDS-Bench** dataset:
- ğŸ”¬ **5 domains** (history, organic chemistry, law, stock research reports,and papers)
- ğŸ“ **17 task types** 
- ğŸ“Š **14,950 high-quality samples**

**Performance Highlights**: Fine-tuning Qwen3 models (0.6B/8B/32B) on a small number of synthesized samples improves reasoning accuracy by **9.2%**. The framework also generates distinct data, challenging existing models on tasks involving tables and formulas, useful for complex benchmark construction.

---

## âœ¨ Key Features

<table>
  <tr>
    <td width="50%">
      <h3>ğŸ“š Data Preprocessing</h3>
      <ul>
        <li>Unified processing of <strong>structured data</strong> (JSON/CSV)</li>
        <li>Support for <strong>unstructured documents</strong> (PDF/PNG/PPT/DOC)</li>
        <li>Triplet conversion and <strong>multimodal content extraction</strong></li>
        <li>Extract text, images, tables, and formulas</li>
      </ul>
    </td>
    <td width="50%">
      <h3>ğŸ•¸ï¸ Knowledge Graph Construction</h3>
      <ul>
        <li><strong>Fully customizable schemas</strong></li>
        <li>Entityâ€“relation constraints</li>
        <li>Complete pipeline: extraction â†’ disambiguation â†’ normalization</li>
        <li>Automated KG construction</li>
      </ul>
    </td>
  </tr>
  <tr>
    <td width="50%">
      <h3>ğŸ’¾ Flexible Storage</h3>
      <ul>
        <li>Multiple backends: <strong>Neo4j</strong>, NetworkX, JSON</li>
        <li>Seamless Neo4j integration</li>
        <li>Visualization and analytics support</li>
        <li>Export to standard formats</li>
      </ul>
    </td>
    <td width="50%">
      <h3>ğŸ¯ Reasoning Data Synthesis</h3>
      <ul>
        <li>Knowledge-graph-driven synthesis</li>
        <li><strong>Subgraph sampling</strong> and path generation</li>
        <li>Entity fuzzification for robustness</li>
        <li>Controllable QA generation with balanced difficulty</li>
      </ul>
    </td>
  </tr>
</table>

### ğŸ“Š Quality Analysis & Evaluation

- ğŸšï¸ **Multidimensional quality assessment**: Support, difficulty, and complexity metrics
- ğŸ“ˆ **Fine-grained analytics**: Token distribution, task types, domain coverage
- ğŸ” **Comprehensive evaluation**: Automated quality scoring and validation

---

## ğŸ” Pipeline

A unified pipeline that preprocesses multimodal data, constructs customizable knowledge graphs, and synthesizes high-quality reasoning datasets with flexible storage and comprehensive quality evaluation.

<div align="center">
  <img src="assets/pipeline.png" alt="MMKG-RDS Pipeline" width="900">
</div>

**Five-Stage Process**:
1. ğŸ“„ **Document Processing** & Knowledge Graph Construction
2. ğŸ”¬ **Data Generation** via Graph Mining
3. ğŸ§¹ **Deduplication** & Quality Scoring
4. ğŸ“¤ **Data Export** to Standard Formats
5. ğŸ¯ **Model Evaluation** & Benchmarking

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+
- LibreOffice (for document conversion)
- CUDA-compatible GPU (recommended)

### 1ï¸âƒ£ Environment Setup

**Step 1: Install LibreOffice**
```bash
sudo apt-get update
sudo apt-get install libreoffice
```

**Step 2: Install Chinese Fonts** (Optional, for Chinese document processing)
```bash
# Check if Chinese fonts are installed
fc-list :lang=zh

# Copy font to system directory
sudo cp ./fonts/msyh.ttf /usr/share/fonts/
sudo fc-cache -fv
```

**Step 3: Install MinerU**
```bash
uv pip install -U "mineru[all]" -i https://mirrors.aliyun.com/pypi/simple
```

**Step 4: Install Python Dependencies**
```bash
uv pip install -U -r requirements.txt
```

### 2ï¸âƒ£ Configuration Setup

Edit the configuration file `configs/dev.yaml`:
```yaml
# éç»“æ„åŒ–æ•°æ®

data:
  input_dir: ./data/dev/ud
  output_dir: ./output_dir
  output_dir: ./output_dir
  structured_data: False
  enable_visual: True

# å¯ç”¨é€šè¿‡å®ä½“ååˆå¹¶å®ä½“
enable_merge_entity_by_name: true

# å¯ç”¨é€šè¿‡å®ä½“åçš„ç›¸ä¼¼åº¦åˆå¹¶å®ä½“
enable_merge_entity_by_sim: False
merge_entity_by_sim:
  threshold: 0.95
  # embedding_model: sentence-transformers/all-MiniLM-L6-v2

# å¯ç”¨é€šè¿‡æ–­è¨€çš„ç›¸ä¼¼åº¦åˆå¹¶æ–­è¨€
enable_merge_assertion_by_sim: true
merge_assertion_by_sim:
  threshold: 0.95
  # embedding_model: sentence-transformers/all-MiniLM-L6-v2

# ç‰ˆå¼è§£æå’ŒKGæŠ½å–ç›¸å…³é…ç½®
dataprocessing:
  enable_assertion_recall: true
  enable_entity_recall: true
  mineru:
    server_url: http://10.178.131.48:30000

  llm:
    api_key: EMPTY
    base_url:  
      - http://10.178.141.79:8000/v1
      - http://10.178.141.233:8000/v1
      - http://10.178.133.1:8000/v1
     
    model: Qwen3-235B-A22B-Instruct-2507
    max_concurrent_requests: 256

  vlm:
    api_key: EMPTY
    base_url: http://10.178.129.197:8000/v1
    model: Qwen3-VL-2B-Instruct
    max_concurrent_requests: 24
    max_tokens: 4096

embedding_model:
  api_key: EMPTY
  base_url: http://10.178.131.43:9000/v1
  model: qwen3_embedding

# æ•°æ®åˆæˆç›¸å…³é…ç½®
subgraph_sampling:
  sampling_algorithm: no_subgraph_sampling
  order: 100
  subgraph_num: 4
  kwargs:
    arg1: value1
    arg2: avlue2


trace_generation:
  selection_method: dfs
  node_types: ['Entity','Table','Image','Formula'] # ['Document','Chunk','Assertion','Entity','Table','Image','Formula']
  max_steps: 4
  num_traces: 4
  min_deg: 0
  max_deg: 200
  mode: in
  kwargs:
    arg1: value1
    arg2: avlue2


data_synthesis:
  api_key: EMPTY
  base_url:  
      - http://10.178.141.79:8000/v1
      - http://10.178.141.233:8000/v1
      - http://10.178.133.1:8000/v1
    
  model: Qwen3-235B-A22B-Instruct-2507
  task_type: multi_hop_tif
  max_concurrent_requests: 5

# QAè´¨é‡è¿‡æ»¤ç›¸å…³é…ç½®
evaluation_models:
  support_models:
    # æ”¯æŒåº¦è¯„ä¼°æ¨¡å‹åˆ—è¡¨ï¼ˆå¯ä»¥é…ç½®å¤šä¸ªï¼Œæ”¯æŒå¤šæ•°æŠ•ç¥¨ï¼‰
    - model: Qwen3-VL-2B-Instruct           # æ”¯æŒåº¦è¯„ä¼°ç”¨æ¨¡å‹åç§°
      base_url: http://10.178.129.197:8000/v1  # æ¨¡å‹æœåŠ¡çš„ HTTP åŸºç¡€åœ°å€
      api_key: EMPTY                        # é‰´æƒç”¨çš„ API Keyï¼ˆæœ¬åœ°æœåŠ¡å¯ä¸ºç©ºæˆ–å›ºå®šå ä½ï¼‰
      max_tokens: 1024                      # å•æ¬¡è°ƒç”¨å…è®¸çš„æœ€å¤§ç”Ÿæˆ token æ•°
    - model: Qwen3-VL-2B-Instruct           # ç¬¬äºŒä¸ªæ”¯æŒåº¦è¯„ä¼°æ¨¡å‹
      base_url: http://10.178.129.197:8000/v1
      api_key: EMPTY
      max_tokens: 1024
    - model: Qwen3-VL-2B-Instruct           # ç¬¬ä¸‰ä¸ªæ”¯æŒåº¦è¯„ä¼°æ¨¡å‹
      base_url: http://10.178.129.197:8000/v1
      api_key: EMPTY
      max_tokens: 1024

  difficulty_models:
    # éš¾åº¦è¯„ä¼°ä½¿ç”¨çš„æ¨¡å‹é…ç½®ï¼Œåˆ†ä¸º strong / weak ä¸¤ä¸ªè§’è‰²
    strong:
      model: Qwen3-VL-2B-Instruct           # strongæ¨¡å‹
      base_url: http://10.178.129.197:8000/v1
      api_key: EMPTY
      max_tokens: 1024
    weak:
      model: Qwen3-VL-2B-Instruct           # weakæ¨¡å‹
      base_url: http://10.178.129.197:8000/v1
      api_key: EMPTY
      max_tokens: 1024

  # æ–°å¢ï¼šå¤æ‚åº¦è¯„ä¼°ä½¿ç”¨çš„å¤§æ¨¡å‹é…ç½®
  complexity_model:
    #è¯„ä¼°evaluate_complexçš„æ¨¡å‹ï¼ˆè´Ÿè´£å¯¹æŒ‡ä»¤å¤æ‚åº¦æ‰“ 1~5 åˆ†ï¼‰
    model: Qwen3-VL-2B-Instruct
    base_url: http://10.178.129.197:8000/v1
    api_key: EMPTY
    max_tokens: 1024

evaluation:
  batch_size: 3        # æ¯æ¬¡å¹¶å‘è¯„ä¼°çš„æ ·æœ¬æ•°é‡
  modes:
    - support               # å¯ç”¨çŸ¥è¯†æ”¯æŒåº¦è¯„ä¼°
    - difficulty            # å¯ç”¨éš¾åº¦è¯„ä¼°
    - complexity            # å¯ç”¨å¤æ‚åº¦è¯„ä¼°

  support:
    mode: majority_vote     # æ”¯æŒåº¦è¯„ä¼°æ¨¡å¼ï¼šmajority_voteï¼ˆå¤šæ¨¡å‹æŠ•ç¥¨ï¼‰æˆ– singleï¼ˆå•æ¨¡å‹ï¼‰
    models: [0, 1, 2]       # ä½¿ç”¨ support_models åˆ—è¡¨ä¸­çš„å“ªäº›æ¨¡å‹ï¼ˆæŒ‰ä¸‹æ ‡é€‰æ‹©ï¼‰

  difficulty:
    mode: strong_weak       # strong_weakï¼ˆå¼ºå¼±æ¨¡å‹åŒæ—¶ä½¿ç”¨ï¼‰ï¼Œä¹Ÿå¯è®¾ä¸º strong_only / weak_only

  complexity:
    enabled: true           # æ˜¯å¦å¯ç”¨å¤æ‚åº¦è¯„ä¼°
```

### 3ï¸âƒ£ Run the Project
```bash
python main.py 
```

**Or run domain-specific examples**:
```bash
# Law domain example
python main_law.py
```

---

## ğŸ“ Project Structure
```
MMKG-RDS/
â”‚
â”œâ”€â”€ ğŸ“„ main.py                          # Main entry point (5-stage pipeline)
â”œâ”€â”€ ğŸ“„ main_law.py                      # Law domain example
â”œâ”€â”€ ğŸ“„ requirements.txt                 # Python dependencies
â”œâ”€â”€ ğŸ“„ README.md                        # Project documentation
â”‚
â”œâ”€â”€ ğŸ“‚ assets/                          # Assets and resources
â”‚   â”œâ”€â”€ logo.png                        # Project logo
â”‚   â”œâ”€â”€ framwork.png                    # Framework diagram
â”‚   â””â”€â”€ pipeline.png                    # Pipeline visualization
â”‚
â”œâ”€â”€ ğŸ“‚ config/                          # Configuration files
â”‚   â”œâ”€â”€ dev.yaml                        # Development config
â”‚   â””â”€â”€ test.yaml                       # Test config
â”‚
â”œâ”€â”€ ğŸ“‚ data/                            # Raw data directory
â”‚   â”œâ”€â”€ chemistry/                      # Chemistry domain data
â”‚   â”œâ”€â”€ law/                            # Law domain data
â”‚   â””â”€â”€ ...                             # Other domains
â”‚
â”œâ”€â”€ ğŸ“‚ schema/                          # Schema definitions
â”‚   â”œâ”€â”€ chemistry.schema                # Chemistry domain schema
â”‚   â””â”€â”€ test.schema                     # Test schema
â”‚
â”œâ”€â”€ ğŸ“‚ processor/                       # Data processing modules
â”‚   â”œâ”€â”€ processor.py                    # Main processor
â”‚   â”œâ”€â”€ node.py                         # Node processing
â”‚   â”œâ”€â”€ edge.py                         # Edge processing
â”‚   â”œâ”€â”€ modal.py                        # Modal data processing
â”‚   â””â”€â”€ chunk.py                        # Text chunking
â”‚
â”œâ”€â”€ ğŸ“‚ data_synthesis/                  # Data synthesis core
â”‚   â”œâ”€â”€ generate_qa.py                  # QA generation
â”‚   â”œâ”€â”€ subgraph_sampling.py            # Subgraph sampling
â”‚   â”œâ”€â”€ trace_generate.py               # Path generation
â”‚   â”œâ”€â”€ information_blur.py             # Entity fuzzification
â”‚   â”œâ”€â”€ filter.py                       # Data filtering
â”‚   â””â”€â”€ constants.py                    # Task definitions
â”‚
â”œâ”€â”€ ğŸ“‚ llms/                            # LLM clients
â”‚   â”œâ”€â”€ client.py                       # OpenAI-compatible client
â”‚   â”œâ”€â”€ vision_client.py                # Vision model client
â”‚   â””â”€â”€ emb.py                          # Embedding client
â”‚
â”œâ”€â”€ ğŸ“‚ eval/                            # Evaluation modules
â”‚   â”œâ”€â”€ eval_up.py                      # LLM evaluation
â”‚   â””â”€â”€ eval_up_vl.py                   # Vision-language evaluation
â”‚
â”œâ”€â”€ ğŸ“‚ qafilter/                        # QA filtering
â”‚   â””â”€â”€ enhanced_refactored_pipeline.py # Enhanced filtering pipeline
â”‚
â”œâ”€â”€ ğŸ“‚ prompts/                         # Prompt templates
â”‚   â”œâ”€â”€ dataprocess_prompt.py           # Data processing prompts
â”‚   â”œâ”€â”€ datasynthesis_prompt.py         # Data synthesis prompts
â”‚   â””â”€â”€ task_prompt.py                  # Task-specific prompts
â”‚
â”œâ”€â”€ ğŸ“‚ util/                            # Utility functions
â”‚   â”œâ”€â”€ pdf2md.py                       # PDF to Markdown
â”‚   â”œâ”€â”€ any2pdf.py                      # Convert to PDF
â”‚   â”œâ”€â”€ json2graph.py                   # JSON to graph
â”‚   â”œâ”€â”€ export2std_data.py              # Export to standard format
â”‚   â””â”€â”€ tool.py                         # Common utilities
â”‚
â””â”€â”€ ğŸ“‚ outputs/                         # Output directory
    â”œâ”€â”€ data_gene.json                  # Generated data
    â”œâ”€â”€ data_filter.json                # Filtered data
    â”œâ”€â”€ data_filter_statistics.json     # Statistics
    â””â”€â”€ graph.graphml                   # Graph data
```

---

## ğŸ“Š Benchmark Results

### MMKG-RDS-Bench Data
<div align="center">
  <img src="assets/benchdata.png" alt="MMKG-RDS Benchmark Results" width="900">
</div>

### Performance of Various Models Across Different Tasks

<div align="center">
  <img src="assets/Performance of Various Models Across Different Tasks.png" alt="MMKG-RDS Benchmark Results" width="900">
</div>

### Fine-tuning Experiments with Synthetic Data
| Model      | Base Accuracy | Fine-tuned Accuracy | Improvement |
| ---------- | ------------- | ------------------- | ----------- |
| Qwen3-0.6B | 39.7%         | 51.5%               | **+11.8%**  |
| Qwen3-8B   | 59.0%         | 65.6%               | **+6.6%**   |
| Qwen3-32B  | 58.7%         | 67.9%               | **+9.2%**   |

---

## ğŸ“š Citation

If you find MMKG-RDS useful in your research, please cite:
```bibtex
@article{mmkg-rds-2026,
  title={MMKG-RDS: Reasoning Data Synthesis via Deep Mining of Multimodal Knowledge Graphs},
  author={Co-authors},
  journal={arXiv preprint arXiv:2026.xxxxx},
  year={2026}
}
```

---

## ğŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guidelines](CONTRIBUTING.md) for details.

---

## ğŸ“„ License

This project is licensed under the Apache License 2.0 - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- Built with [MinerU](https://github.com/opendatalab/MinerU) for document processing
- Knowledge graph storage powered by [Neo4j](https://neo4j.com/)
- LLM integration via [OpenAI API](https://openai.com/)

---

<div align="center">
  
  **â­ Star us on GitHub â€” it motivates us a lot!**
  
  [Report Bug](https://github.com/360AILAB-NLP/MMKG-RDS/issues) Â· [Request Feature](https://github.com/360AILAB-NLP/MMKG-RDS/issues) Â· [Documentation](https://mmkg-rds.readthedocs.io/)
  
</div>